---
title: "Dismantling the bulk: examining neuronal heterogeneity using single-cell techniques"
author: Sara Linker, Apua Paquola, Roger Lasken, and Keegan Korthauer
date: 9/6/2016
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(out.width='750px', out.height='750px', dpi=300,
                      fig.height=7, fig.width=7)
knitr::opts_knit$set(root.dir="~/FestivalWorkshopSC/BrainAtlas")
```

### Welcome to the Festival of Genomics workshop on single-cell analyses

This is an R Markdown document that contains instructions and code for the examples used in todays workshop.  The first few steps will check that you have all the packages and data files necessary to carry out all of the analyses.

# Hour 1: Getting Started
Sara's section
...

### Check that the Brain Atlas data files are present

The following code chunk assumes that Brain Atlas files have been downloaded and placed in the "BrainAtlas" subdirectory of a folder in your home directory entitled "FestivalWorkshopSC".  If you have downloaded these files to another location, either create a new folder and move the files there, or substitute the file path to where they are currently located for "~/FestivalWorkshopSC/BrainAtlas".  If you are using the RStudio Server instance provided by the workshop, change the first line that follows to `setwd("/home/FestivalWorkshopSC/BrainAtlas")`

```{r Check for data files, eval=TRUE, echo=TRUE}
setwd("~/FestivalWorkshopSC/BrainAtlas")
file.exists("cell_metadata.csv")
file.exists("genes_counts.csv")
file.exists("README.txt")
```

If any of the preceding lines return `FALSE`, double check that you have set the correct working directory and that all download files have been placed in that folder.  If they are missing, you can download the files [here](http://casestudies.brain-map.org/celltax/download_archive).  Note that there will be more files than listed here (including alternate gene count quantifications, and metadata about data-driven cluster memberships as discussed in the paper ["Adult mouse cortical cell taxonomy revealed by single cell transcriptomics"](http://www.nature.com/neuro/journal/v19/n2/full/nn.4216.html)), but these are the ones we will make use of.

### Read the Brain Atlas data files into R

The `read.csv` function in R is useful for reading in .csv (comma-separated value) files.  First, we'll read in the main data file `genes_counts.csv` to a data frame using this function and check its contents.  The extra arguments to this function help to format our object so that we have row and column names, and we use character variables instead of converting to factors.  For more details on these arguments, you can type `help(read.csv)`.  In the resulting `coutns` object, we have genes in rows (24057) and cells in columns (1679).

```{r Read in Counts, eval=TRUE, echo=TRUE}
counts <- read.csv("genes_counts.csv", stringsAsFactors = FALSE, header=TRUE, row.names = 1)
str(counts[,1:20]) # restrict to the first 20 columns (cells) 
```

The `cell_metadata.csv` file contains 1679 rows (one for each cell) and columns containing information such as collection date, sequencing type, total reads, mapping percentage, dissection layer, and major/minor derived cell subtypes. 

```{r Read in Cell Metadata, eval=TRUE, echo=TRUE}
cells <- read.csv("cell_metadata.csv", stringsAsFactors = FALSE, header = TRUE)
str(cells)
```

More detailed information about the files downloaded from the Allen Brain Atlas can be found in the `README.txt` file provided.  Here is a peek at the contents of that file.

```{bash Peek at README.txt file, eval=TRUE, echo=TRUE}
# This is a bash command, to be executed at the command line (not within R);
# Alternatively, simply open the README.txt in your favorite text editor to view its contents
head README.txt
```

### Check that the desired R packages have been installed

Once a list of desired R packages is finalized, can check that they are installed with 

```{r Check for desired packages, eval=TRUE, echo=TRUE, results="hide", message=FALSE, warning=FALSE}
require(scde)     #bioconductor
require(monocle)  #bioconductor
require(sincell)  #bioconductor
require(scDD)     #github
require(ggplot2)  #cran
require(devtools) #cran
require(Oscope)
```

If any of these commands return a message that includes "there is no package called...", then the package is missing and needs to be installed.  Note that packages may be stored in one of several package repositories.  The most popular are Bioconductor, github, and CRAN.  For Bioconductor packages, for example ```edgeR```, this can be done with the following code:

```{r install bioconductor package, echo=TRUE, eval=FALSE, results="hide", message=FALSE}
source("http://bioconductor.org/biocLite.R")
biocLite("monocle")
```

For CRAN packages, for example ```devtools```, installation can be done with the following code:

```{r install cran packages, echo=TRUE, eval=FALSE}
install.packages(devtools)
``` 

For Github packages, for example ```scDD```, installation can be done with the following code:

```{r install github packages, echo=TRUE, eval = FALSE}
install.packages("devtools")
devtools::install_github("kdkorthauer/scDD")
```

### Visualize major axes of variation in a PCA plot

```{r PCA, eval = TRUE, echo = TRUE}
# extract top 500 variable genes
gene.var <- apply(counts, 1, function(x) var(log(x[x>0])))
counts.top500 <- counts[which(rank(-gene.var)<=500),]

counts.pca <- prcomp(log(counts.top500+1),
                   center = TRUE,
                   scale. = TRUE) 
summary(counts.pca)$importance[,1:5]
plot(counts.pca, type="l", main="Top 10 PCs")

color_class <- rainbow(length(unique(cells$major_class)))
plot(counts.pca$rotation[,1], counts.pca$rotation[,2], 
      xlab="PC 1", ylab="PC 2", col=color_class[as.numeric(factor(cells$major_class))], pch=20,
      main="PCA plot of cells colored by derived major class")

color_class <- rainbow(length(unique(cells$layer_dissectoin)))
plot(counts.pca$rotation[,1], counts.pca$rotation[,2], 
      xlab="PC 1", ylab="PC 2", col=color_class[as.numeric(factor(cells$layer_dissectoin))], pch=20,
      main="PCA plot of cells colored by Dissection Layer")
```

# Hour 2: Normalization and Quality Control of scRNA-seq
Apua's Section 
...

### Normalization

...

### Quality Control (QC measures)

```{r Detection Rate, eval = TRUE, echo = TRUE}
detectionRate <- apply(counts, 2, function(x) sum(x > 0) / length(x))
hist(detectionRate)
```

...


# Hour 3: Analysis Modules

Keegan's Section
...

### Identify the highly variable genes

In this module, we will identify genes that are highly variable across the entire cell population.  This will give us a subset of genes to focus on that is likely enriched for those that are driving heterogeneity among cellular subtypes.  

For ease in downstream analysis with various R packages we'll make use of today, we'll convert the data.frames that currently (separately) house the counts and cell metadata into a Bioconductor object called an SCDESet introduced by the ```scater``` package.  This object is a container that can hold raw and normalized expression values, along with the metadata for both samples and genes, in one place.  We'll also perform some basic preprocessing and normalization here to adjust for library size using the pool and deconvolve method in the ```scran``` package, as well as remove genes with expression in only a few cells (*** these steps may not be necessary if this was already carried out in Apua's section... Can refer back to the section or remove if it is redundant ***).

```{r Preprocess with scater and scran, eval = TRUE, echo = TRUE}
library(scater)
library(scran)
rownames(cells) <- cells$long_name
eset <- newSCESet(countData = counts, phenoData = AnnotatedDataFrame(cells))  

# normalize counts for library size using the pool & deconvolve method of Lun et al. (2016)
eset <- computeSumFactors(eset, sizes=c(20, 40, 60, 80))
summary(sizeFactors(eset))
plot(sizeFactors(eset), colSums(counts(eset))/1e6, log="xy",
    ylab="Library Size (Total Counts in Millions)", xlab="Pooled Size Factor Estimate",
    main="Normalization factor versus library size")

# filter out low-abundance genes (at least 10 cells out of 1679 must have nonzero expression)
keep <- rowSums(exprs(eset)) >= 10
eset <- eset[keep,] 
sum(keep)

# use the size factors calculated above to normalize the counts - these get placed in the 'exprs' slot
eset <- normalize(eset)
```

Next, we'll perform some calculations to help us identify genes that have high variability.  To do so, we have to take into account the relationship between mean expression level and variance of expression level (also commonly referred to as 'dispersion' in the literature).  Namely, that what we observe in RNA-seq count data is that genes with higher expression have higher variance.  This is also a property of the Negative Biomial distribution, which is often used to model count data from RNA-seq experiments.  

We use the ```trendVar``` function of the ```scran``` package to estimate the relationship between the mean and variance (dispersion). This function fits a smooth type of curve to capture the trend in mean log-expression and variance log-expression, which will serve as an estimate of the baseline technical variability if we assume that the majority of the genes are constantly expressed (i.e. that there is no significant biological variability).  Note that this is a rather large assumption, and it is not necessarily true in our experiment.  How might this assumption be evaluated?  It is ideal to independently estimate this relationship for so-called 'spike-in' data (where a small number of artifical transcripts have been added at known concentrations such that any variability is assured to be technical).  However, these can be challenging to use and won't necessarily capture all of the technical variability depending on where in the protocol they are added.  Since we do not have spike-ins in our dataset, we proceed by estimating this relationship on the entire gene set, by using the ```use.spikes=FALSE``` option in the ```trendVar``` function.  

Once this relationship has been estimated, the ```decomposeVar``` (also in the ```scran``` package) essentially removes the estimated technical variability component from the total variability to calculate the estimated biological variability.  This is what we aim to use to find the highly variable genes.  We also visualize the mean and variance log-expression relationship, along with the estimated technical variabilty fit.  

```{r Indentify Variable Genes, eval=TRUE, echo=TRUE}
var.fit <- trendVar(eset, trend="loess", use.spikes=FALSE, span=0.2)
var.out <- decomposeVar(eset, var.fit)

# plot the mean versus variance of log-expression, along with the technical variance fit
plot(var.out$mean, var.out$total, pch=16, cex=0.6, xlab="Mean log-expression", 
    ylab="Variance of log-expression")
o <- order(var.out$mean)
lines(var.out$mean[o], var.out$tech[o], col="dodgerblue", lwd=2)
```

Finally, we extract the top 2000 genes with highest biological variability to use in downstream analyses.  We also take a look at the distributions of normalized log-expression values for the top 20 biologically variable genes.  Note that the biological variability estimates provided by \Rcode{decomposeVar} seem to be rather robust to outlier cells, as none of the genes with highest variability seem to be driven by outliers.  Note that there exist methods to find **significantly** highly variable genes in scRNA-seq data, however, without some other independent estimate of technical variability, we don't have anything to compare to in order to establish significance.  What is an example of an independent measurement of technical variability? 

```{r Extract Variable Genes, eval=TRUE, echo=TRUE}
# extract and examine the top 2000 genes by biological variance
top.hvg <- order(var.out$bio, decreasing=TRUE)[1:2000]
head(var.out[top.hvg,])

# construct a new eset object that only contains the highly variable genes for downstream analysis
eset.hvg <- eset[top.hvg,]

# plot distribution of the top 20 highly variable genes
top20 <- top.hvg[1:20]
boxplot(t(exprs(eset)[top20,]), las=2, ylab="Normalized log-expression", col="dodgerblue", main="Top 20 Highly Variable Genes")
```

Scanning the names of the top 20 highly variable genes, note that *Gad1, Cnr1, Arpp21, Sparcl1, Npy, Nfib,* and *Vip* are all in the list of 228 well-known neuronal subtype/non-neuronal marker genes listed in Supplementary Table 9.  What does this tell us about our experiment?

### Identify differentially expressed genes

```{r DE, eval = TRUE, echo = TRUE}
library(scde)
library(scDD)
```
...

### Order cells by "Psuedotime" (temporal-spatial variation)

```{r Pseudotime, eval = TRUE, echo = TRUE}
library(monocle)
```
...

### Identify genes with oscillating expression patterns

```{r Oscillating genes, eval = TRUE, echo = TRUE}
library(Oscope)
```

TODO: Fill in the above analysis modules ...

```{r Extract Code Snippets, eval = FALSE, echo = FALSE}
# This snippet just generates a .R file that only contains the code snippets within this document
# Not executed; need to run separately to update the .R file after this file is modified ...
library(knitr)
knitr:::purl("~/Desktop/scRNAseq/FestivalWorkshop2016/FestivalWorkshopVignettes/SingleCellAnalyses.Rmd",  
     output="~/Desktop/scRNAseq/FestivalWorkshop2016/FestivalWorkshopVignettes/SingleCellAnalyses.R")
```
